\documentclass[a4paper,11pt,notitlepage]{report}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{bibgerm}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{color}
\usepackage{enumerate}
\usepackage{tabularx}
\usepackage{subfig}
\usepackage{fancyhdr}
\usepackage[pdftex,pdfpagelabels,colorlinks,backref,pagebackref]{hyperref}
\usepackage{tikz} % SELBST HINZUGEFÜGT
\usepackage{slashbox}
% == Set the heading style ===================================================
\setlength{\headheight}{14pt}
\pagestyle{fancyplain}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\lhead[\fancyplain{}{\thepage}]{\fancyplain{}{\rightmark}}
\rhead[\fancyplain{}{\leftmark}]{\fancyplain{}{\thepage}}
\cfoot{}
\renewcommand{\headrulewidth}{0.4pt}
% ============================================================================

% == Set correct values for fitting floats ===================================
\tolerance=2000
\emergencystretch=10pt

\setcounter{topnumber}{3}
\setcounter{totalnumber}{5}
\setcounter{bottomnumber}{2}

% To make those darn floats fit where they should
\setcounter{totalnumber}{9}
\setcounter{topnumber}{9}
\setcounter{bottomnumber}{9}
\renewcommand{\textfraction}{0.00}
\renewcommand{\topfraction}{1.0}
\renewcommand{\bottomfraction}{1.0}
% ============================================================================

% == German definitions for theorems etc. ==================================== 
\newtheorem{definition}{Definition}[chapter]
\newtheorem{theorem}{Satz}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{corollary}{Korollar}[chapter]
\newtheorem{observation}{Beobachtung}[chapter]
\newtheorem{fact}{Fakt}[chapter]
\newtheorem{remark}{Bemerkung}[chapter]
\newtheorem{example}{Beispiel}[chapter]
% ============================================================================

% == Abkürzungen für die reellen, natürlichen, ganzen,... Zahlen =============
\newcommand{\R}{{\ensuremath{\mathbb{R}}}}
\newcommand{\N}{{\ensuremath{\mathbb{N}}}}
\newcommand{\Z}{{\ensuremath{\mathbb{Z}}}}
\newcommand{\C}{{\ensuremath{\mathbb{C}}}}
\newcommand{\Q}{{\ensuremath{\mathbb{Q}}}}
\newcommand{\F}{{\ensuremath{\mathbb{F}}}}
\newcommand{\Prim}{{\ensuremath{\mathbb{P}}}}
\newcommand{\E}{{\ensuremath{\mathbb{E}}}}
% ============================================================================

% == Makros für Autorenname und -adresse =====================================
\newcommand{\myaddress}[6]{%
  \parbox{\textwidth}{\textbf{\large #1}\\
    #2\\ #3\\ #4\\ 
    \ifthenelse{\equal{#5}{}}{}{Email: \href{mailto:#5}{\texttt{#5}}\\}
    \ifthenelse{\equal{#6}{}}{}{WWW: \href{#6}{\path|#6|}\\}
  } 
}

\newcommand{\myauthor}[1]{%
  \addtocontents{toc}{\protect\hspace{3.35ex}%
  \textsl{#1}\par}\vspace{-4ex}\quad\hfill\textsl{\Large #1}\vspace{8ex}}

\newcommand{\myname}[1]{\Large #1}

\title{\textbf{{Einführung in die Stochastik - Mitschrieb} \\[5ex] 
    {\Large Vorlesung im Wintersemester 2011/2012\\[5ex]}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tragen Sie in der folg. Zeile Ihren Namen ein: %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{\myname{Sarah Lutteropp}}

\begin{document}
\shorthandoff{"}
\maketitle
\setcounter{tocdepth}{1}
\tableofcontents

\section*{Vorwort}
Dies ist ein sporadischer Mitschrieb der Übung “Einführung in die Stochastik” vom Wintersemester 2011/2012 am Karlsruher Institut für Technologie.

\chapter{24.11.11}

\subsection{Aufgabe 16}
\begin{proof}
	weiterhin gilt
	$$B^{i_1, \ldots, i_k}=\bigcap\limits_{\mu = 1}^k{A_{i_\mu}} \cap \bigcap\limits_{\nu \notin\{i_1, \ldots, i_k\}}{A_\nu^c}$$
	$$\Rightarrow 1_{\{X=k\}} = \sum\limits_{1 \leq i_1 < \ldots < i_k \leq n}{1_{B^{i_1, \ldots, i_k}}}$$
	$$= \sum\limits_{1 \leq i_1 < \ldots < i_k \leq n}{\prod\limits_{\mu=1}^k{1_{A_{i_\mu}}} \prod\limits_{\nu \notin\{i_1, \ldots, i_k\}}{(1-1_{1_\nu})}}$$
	allgemein gilt für  Funktionen $f$, $g$:
	$$\prod\limits_{\nu}^m{(f_\nu + g_\nu)} = \sum\limits_{r=0}^m{\sum\limits_{1 \leq i_1 < \ldots < i_r \leq m}{\prod\limits_{\nu = 1}^r{g_\nu} \prod\limits_{\mu \notin \{i_1, \ldots, i_r\}}{f_\mu}}}$$
	(Beweis mit vollst. Induktion über $m$)
	\newline
	hier $f_\nu \equiv 1, g_\nu \equiv -1_{A_\nu}$
	$$\Rightarrow \prod\limits_{\nu \notin\{i_1, \ldots, i_k\}}{(1-1_{A_\nu})} = \prod\limits_{\nu = j_1, \ldots, j_{n-k}}{(1-1_{A_\nu})}$$
		(wobei $\{j_1, \ldots, j_{n-k}\} = \{1,\ldots,n\} \backslash \{i_1, \ldots, i_k\}$)
	$$= \prod\limits_{\nu=1}^{n-k}{(1-1_{A_\nu})}$$
	$$= \sum\limits_{r=0}^{n-k}{\sum\limits_{1 \leq i_1 < \ldots < i_r \leq n}{\underbrace{\prod\limits_{\nu = 1}^r{(-1_{A_\nu})}}_{= (-1)^r \prod\limits_{\nu = 1}^r{1_{A_\nu}}} \cdot 1}}$$
	$$\Rightarrow 1_{\{X=k\}} = \sum\limits_{r=0}^{n-k}{\sum\limits_{1 \leq i_1 < \ldots < i_k \leq n}{\sum\limits_{1 \leq i_1 < \ldots < i_r \leq n, i_1, \ldots, i_r \notin \{i_1, \ldots, i_k\}}{\prod\limits_{\mu = 1}^k}{1_{A_{i_\mu}}}\prod\limits_{\nu = 1}^r{1_{A_{i \nu}}}}}$$
	statt erst $k$, dann weitere $r$ Indizes zu wählen, wähle nun direkt $(k+r)$ Indizes $\leadsto {k+r \choose k}$ Möglichkeiten
	\newline
	(z.B. für die Wahl der Indizes $1,2,3$ gibt es für $k=1$ die Möglichkeiten
	$$i_1 = 1, \quad j_1,j_2=2,3$$
	$$i_1 = 2, \quad j_1,j_2 = 1,3$$
	$$i_1 = 3, \quad j_1, j_2 = 1,2)$$
	$$\Rightarrow 1_{\{X=k\}} = \sum\limits_{r=0}^{n-k}{(-1)^r(\sum\limits_{1 \leq i_1 < \ldots < i_{k+r} \leq n}{\prod\limits_{\mu = 1}^{k+r}{1_{A_{i_\mu}}) \cdot ({k+r \choose k})})}}$$
	$$\Rightarrow P(X=k)=E(1_{\{X=k\}})$$
	$$= \sum\limits_{r=0}^{n-k}{(-1)^r{k+r \choose k} \sum\limits_{1 \leq i_1 y \ldots < i_{k+r}\leq n}{P(A_{i_1}\cap \ldots \cap A_{i_{k+r}})}}$$
	$j=r+k:$
	$$= \underbrace{\sum\limits_{j=k}^n{(-1)^{j-k}{j \choose k}S_j}}_{{k+r \choose k}={k+r \choose r} = {j \choose j-k} = {j \choose k}}$$
\end{proof}

\subsection{Zusatz 1}
\paragraph{Modell}
Fächer von 1 bis $n$ nummeriert.
Es werden $k$ Kugeln auf diese Fächer verteilt (gleichwahrscheinlich)
$$X_{n,k} \hat{=} \text{ Anzahl der Fächer, die leer geblieben sind}$$
$$\Omega = \{ \omega = (\omega_1, \ldots, \omega_k) \colon 1 \leq \omega_i \leq n\} = \{1, \ldots, n\}^k$$
$$P \text{ Gleichverteilung auf } \Omega$$
$$A_j = \{\text{j-tes Fach leer geblieben} \}$$
$$\Rightarrow X_{n,k} = \sum\limits_{j=1}^n{1_{A_j}}$$
Sei nun $1 \leq i_1 < \ldots < i_r \leq n$.
$$\bigcap\limits_{\nu=1}^r{A_{i_\nu}} = \{ \omega \colon \omega_1, \ldots, \omega_k \in \{1, \ldots,n\} \backslash \{i_1, \ldots, i_k\}\}$$
$$\Rightarrow P(\bigcap\limits_{\nu = 1}^r{{A}_{i_\nu}}) = \frac{(n-r)^k}{n^k} = \left(1-\frac{r}{n}\right)^k$$
$$\Rightarrow P(X_{n,k}=1) = \sum\limits_{r=j}^n{(-1)^{r-j}{r \choose j}\underbrace{S_r}_{{n \choose r}(1- \frac{r}{n})^k}}$$

\subsection{Aufgabe 12}
$\Omega = Per_{n, \neq}^n$
$$A_j = \{(a_1, \ldots, a_n) \in \Omega \colon a_j \geq 1\}$$
$$E(\sum\limits_{j=2}^n{1_{A_j}}) = \sum\limits_{j=2}^n{\underbrace{E(1_{A_j})}_{=P(A_j)}}$$
Berechne für $j=1, \ldots, n$
$$P(A_j)$$
$$|A_j| = \underbrace{n-j+1}_{\text{Möglichkeiten, den j-ten Eintrag festzulegen}} \cdot \underbrace{|Per_{n-1, \neq}^{n-1}|}_{=(n-1)!}$$
$$|\Omega| = n! \Rightarrow P(A_j) = \frac{n-j+1}{n}$$
$$\Rightarrow E\left( \sum\limits_{j=2}^n{1_{A_j}} \right)= \frac{1}{n} \sum\limits_{j=2}^n{(n-j+1)}$$
$$= \frac{1}{n}(n-1)(n+1) + \frac{1}{n}\underbrace{\sum\limits_{j=2}^n{(-j)}}_{= - \sum\limits_{j=1}^n{j}+1 = -\frac{n(n+1)}{2}+1}$$
$$=\ldots=\frac{n-1}{2}$$

\subsection{Aufgabe 15}
r rote, s schwarze Kugeln
\newline
nach dem Ziehen die Kugel und $c \in \{-1,0,1,\ldots\}$ zusätzliche zurücklegen.
$$\Omega := \Omega_1 \times \Omega_2 = \{0,1\}^2$$
$$0 \hat{=} \text{ schwarz}$$
Startverteilung:
$$p_1 \colon \Omega_1 \rightarrow [0,1]:$$
$$p_1(0):=\frac{s}{r+s}, p_1(1)=\frac{r}{r+s}$$
Übergangsverteilung:
$$p_2(0|0) = \frac{s+c}{r+s+c}, p_2(1|0) = \frac{r}{r+s+c}$$
$$p_2(0|1)= \frac{s}{r+s+c}, p_2(1|1)=\frac{r+c}{r+s+c}$$
$$z.B. P\left((0,1)\right) = p_1(0) \cdot p_2(1|0)= \frac{s}{r+s}\frac{r}{r+s+c}$$

\chapter{08.12.2011}
\section{A17}
Aufgabe in anschaulich: \url{http://www.mister-mueller.de/mathe/beispiele/ziege/ziege5.html}
\newline
Dreistufiges Experiment. \newline
$\Omega_1=\{1,2,3\}$ \newline
$S_1$ ZV, die die erste Wahl des Spielers angibt. \newline
Es gilt $\Prim(S_1 = i) = \frac{1}{3} (i = 1,2,3)$. \newline
oBdA sei der Gewinn hinter Tür 1. \newline
$\Omega_2 = \{2,3\}, \Omega_3 = \{1,2,3\}$ \newline
$M$ bezeichne die Wahl des Moderators (welche Tür er öffnet). \newline
$S_2$ bezeichne die zweite Auswahl ds Spielers.
\begin{enumerate}
	\item die bedingte Verteilung von $M$ unter $S_1$ ist gegeben durch
	$$\Prim(M=2 | S_1 = 1) = \Prim(M=3|S_1 = 1) = \frac{1}{2}$$
	$$\Prim(M=3 | S_1 = 2) = 1, \Prim(M=2| S=2) = 0$$
	$$\Prim(M=2 | S_1=3) = 1, \Prim(M=3| S=3)=0$$
	% 8 Uhr morgens Z2 tut
	Dies ergibt die gemeinsame Verteilung von $M$ und $S_1$:
	allgemein: $\Prim(M=j|S_1 = k) = \frac{\Prim(M=j, S_1 = k)}{\Prim(S_1=k)}$
	$$\Rightarrow \Prim(M=2,S=2) = \Prim(M=3,S=3) = 0$$
	$$\Prim(M=2, S_1 = 1) = \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{6}$$
	$$\Prim(M=3, S_1 = 1) = \frac{1}{6}$$
	$$\Prim(M=3, S_1 = 2) = 1 \cdot \frac{1}{3} = \frac{1}{3}$$
	$$\Prim(M=2, S_1 = 3) = \frac{1}{3}$$
	Die bedingte Verteilung von $S_2$ unter $(S_1,M)$ ist gegeben durch 
	$$\Prim(S_2 = 3| S_1 = 1, M=2) = \Prim(S_2 = 2| S_1 = 1, M=3)$$
	$$= \Prim(S_2 = 1 | S_2 = 2, M=3) = \Prim(S_2 = 1 | S_1 = 3, M = 2)$$
	$$= 1$$
	$$\Rightarrow \Prim(S_2 = 1)$$ $$= \Prim(S_2 = 1 | S_1 = 2, M = 3) \cdot \Prim(S_1 = 2, M= 3) + \Prim(S_2 = 1 | S_1 = 3, M = 2) \cdot \Prim(S_1 = 3, M= 2)$$
	(Formel der totalen Wahrscheinlichkeit)
	$$\Rightarrow \Prim(S_2=1) = 1 \cdot \frac{1}{3} + 1 \cdot \frac{1}{3} = \frac{2}{3}$$
	Wahrscheinlichkeit, dass der Spieler gewinnt.
	\item jetzt
		$$\Prim(M=2| S_1 = i)$$
		$$= \Prim(M=3 | S_1 = i) = \frac{1}{2} (i=1,2,3)$$
		$$\Rightarrow \Prim(M=k, S_1 = i)$$
		$$= \Prim(M=k|S_1 = i) \cdot \Prim(S_1 = i)$$
		$$= \frac{1}{2} \cdot \frac{1}{3} = \frac{1}{6} \qquad (k=1,2; \quad i = 1,2,3)$$
		$$\Prim(S_2 = j | M=k, S_1 = i) \text{ wie oben}$$
		und zusätzlich
		$$\Prim(S_2 = 1 | M= 2, S_1 = 2)$$
		$$= \Prim(S_2 = 3 | M=2, S_1 = 2) = \frac{1}{2}$$ 
		$$\Prim(S_2 = 1 | M=3, S_1 = 3)$$
		$$= \Prim(S_2 = 2 | M = 3, S_1 = 3) = \frac{1}{2}$$
		$$\Rightarrow \Prim(S_2 = 1)$$
		$$= \Prim(S_2 = 1 | S_1 = 2, M = 3) \cdot \Prim(S_1 = 2, M = 3)$$ $$+ \Prim(S_2 = 1 | S_1 = 3, M = 2) \cdot \Prim(S_1 = 3, M = 2)$$ $$+ \Prim(S_2 = 1 | S_1 = 2, M = 2) \cdot \Prim(S_1 = 2, M = 2)$$ $$+ \Prim(S_2 = 1 | S_1 = 3, M = 3) \cdot \Prim(S_1 = 3, M = 3)$$
		$$= 1 \cdot \frac{1}{6} + 1 \cdot \frac{1}{6} + \frac{1}{2} \cdot \frac{1}{6} + \frac{1}{2} \cdot \frac{1}{6} = \frac{1}{2}$$
\end{enumerate}

\section{A18}
Die Ereignisse $W_1, \ldots, W_6$ seien definiert durch
$$W_i = \text{"i wird geworfen"}$$
$$A = \text{"im ersten Zug wird eine rote Kugel gezogen"}$$
$$\Rightarrow \Prim(A | W_i) = \begin{cases} \frac{r-i}{r+s}, & i \text{ gerade} \\ \frac{r+i}{r+s}, & i \text{ ungerade} \end{cases}$$
$$= \frac{r- (-1)^i i}{r+s}, i = 1, \ldots, 6$$ 

Es gilt 
$$\Prim(A) = \sum\limits_{i=1}^6{\Prim(A|W_i) \cdot \Prim(W_i)}$$
$$ = \frac{2r-1}{2(r+s)}$$

$$B = \text{"im zweiten Zug wird eine rote Kugel gezogen"}$$
$$\Rightarrow \Prim(B) = \frac{2r-1}{2(r+s)}$$
und $$\Prim(A \cap B) = \Prim(A) \cdot \Prim(B) \text{ (Ziehen mit Zurücklegen)}$$
$$\Rightarrow \Prim(A \cap B) = \left(\frac{2r-1}{2(r+s)}\right)^2$$
die Wkt, dass beide gezogenen Kugeln rot sind.
$$C = \text{"im 2. Zug wird schwarz gezogen"}$$
$$\Rightarrow C = B^c$$
d.h. $A$ und $C^c$ sind unabhängig.
$$\Rightarrow A \text{ und } C \text{ sind unabhängig}$$

\newpage

\section{A19}
$$G_k = \text{"$I_k$ wurde gesendet"}$$
$$E_k = \text{"$I_k$ wurde empfangen"}$$
\begin{enumerate}
	\item $$\Prim(\text{"es wird eine Information empfangen, die nicht gesendet wurde"})$$
	$$=\sum\limits_{k=1}^4{\Prim(E_k^c | _k) \cdot \Prim(G_k)}$$
	$$= \sum\limits_{k=1}^4{\Prim(G_k^c | E_k) \cdot \Prim(E_k)}$$
	$$\Prim(E_k^c|G_k) = 1- \Prim(E_k | G_k) = \frac{k}{k+1}$$
	$$\Prim(G_k) = \frac{1}{4}$$
	$$\Rightarrow p = \frac{1}{4} \sum\limits_{k=1}^4{\frac{k}{k+1}} = \frac{1}{4} \cdot \left (\frac{1}{2} + \frac{2}{3} + \frac{3}{4} + \frac{4}{5} \right )$$
	$$= \frac{1}{4} \cdot \left( \frac{30+40+45+48}{60} \right ) = \frac{163}{240} \approx 68 \%$$
	\item $$\Prim(G_k | E_k)$$
	$$= \frac{\Prim(G_k, E_k)}{\Prim(E_k)} = \frac{\sum\limits_{i=1}^4{\Prim(G_k, E_k | G_i) \cdot \Prim(G_i)}}{\sum\limits_{k=1}^4{\Prim(E_k | G_i) \cdot \Prim(G_i)}}$$

$$= \frac{\Prim(E_k | G_k) \Prim(G_k)}{\sum\limits_{i=1}^4{\Prim(E_k|G_i) \cdot \Prim(G_i)}}$$
$$= \frac{\frac{1}{4} \cdot \frac{1}{k+1}}{\sum\limits_{i\neq k, i = 1, \ldots, 4}{\Prim(E_k|G_i) \cdot \Prim(G_i) + \Prim(E_k | G_i) \Prim(G_k)}}$$
$$= \frac{\frac{1}{4(k+1)}}{\sum\limits_{i \neq k}{\frac{i}{3(i+1)} \cdot \frac{1}{4} + \frac{1}{k+1} \cdot \frac{1}{4}}}$$
d.h.
$$\Prim(G_1 | E_1) = \frac{\frac{1}{4 \cdot 2}}{(\frac{3}{9} + \frac{3}{12} + \frac{4}{15}) \cdot \frac{1}{4} + \frac{1}{2} \cdot \frac{1}{4}}$$
$$= \frac{\frac{1}{2}}{\frac{1}{2}+\frac{2}{3}+\frac{3}{12}+\frac{4}{15}} = \frac{90}{223} \approx 40,4 \%$$
analog ergibt sich
$$\Prim(G_2|E_2) = \frac{20}{61}$$
$$\Prim(G_3 | E_3) = \frac{45}{163}$$
$$\Prim(G_4 | E_4) = \frac{36}{151}$$
\end{enumerate}

\section{A20}
$X_1, X_2 \overset{u.i.v.}{\sim} U(\{-1,1\})$
$$Z:= X_1 X_2$$
\begin{enumerate}
	\item $$\Prim(Z=1) = \Prim(X_1 = X_2 = 1) + \Prim (X_1 = X_2 = -1)$$
	$$= \Prim(X_1 = 1) \cdot \Prim(X_2 = 1) + \Prim(X_1 = 1) \cdot \Prim(X_2 = -1)$$
	$$= \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{2}$$
	$$\Prim(Z=-1) = \frac{1}{2}$$
	$$\Prim(Z=1, X_1 = 1) = \Prim(X_1 X_2 = 1, X_1 = 1)$$
	$$= \Prim(X_2 = 1, X_1 = 1) = \frac{1}{4}$$
	$$= \Prim(Z=1) \cdot \Prim(X_1 = 1)$$
	analog $\Prim(Z=-1, X_1 = 1) = \Prim(Z = -1) \Prim(X_1 = -1)$
	$$\Prim(Z=1, X_1 = -1) = \frac{1}{4} = \Prim(Z=1) \Prim( X_1 = -1)$$
	$$\Prim(Z=-1, X_1 = -1) = \Prim(Z=-1) \cdot \Prim(X_1 = -1)$$
	$$\Rightarrow Z \text{ und } X_1 \text{ sind unabhängig.}$$
	analog: $Z$ und $X_2$ sind unabhängig.
	\item $$\Prim(X_1 = 1, X_2 = 1, Z=1)$$
	$$= \Prim(X_1 = 1, X_2 = 1)$$
	$$= \frac{1}{4}$$
	aber $\Prim(X_1 = 1) \cdot \Prim(X_2 = 1) \cdot \Prim(Z=1) = \frac{1}{8}$
	$$\Rightarrow X_1, X_2 \text{ und } Z \text{ sind \underline{nicht} unabhängig.}$$
	\item $$\E(X_1 \cdot X_ 2\cdot Z)= \E (Z^2) = 1$$
\end{enumerate}

\chapter{19.01.2012}
SGGZ
\newline
$X_1, X_2, \ldots$ unabhängig mit gleicher Verteilung, wobei $\E X_1^2 < \infty$.
$$\bar{X_n}:= \frac{1}{n} \sum\limits_{i=1}^{n}{X_i}$$
Dann gilt:
$$\lim\limits_{n \rightarrow \infty}{\Prim(|\bar{X_n}-\E X_1| \geq \epsilon)} = 0 \quad \forall \epsilon > 0$$

\section{A27}
a) $X_1, X_2, \ldots$ Folge von ZVen mit $V(X_j) \leq M < \infty \quad \forall j \in \N, \E(X_j) = m \quad \forall j \in \N.$
$$\exists k \in \N \quad \forall i,j \in \N \colon (|i-j| \geq k \Rightarrow C(X_i, X_j) = 0)$$
nach Vorlesung gilt:
$$C(X_i, X_j) \leq \sqrt{\underbrace{Var(X_i)}_{\leq M} \underbrace{Var(X_j)}_{\leq M}} \leq M$$
$V(\bar{X_n})$
$$= V(\frac{1}{n} \sum\limits_{i=1}^n{X_i}) = \frac{1}{n^2} \cdot \sum\limits_{i=1}^n{V(X_i)} + \frac{1}{n^2 \sum\limits_{i,j = 1, i \neq j}^n{Cov(X_i, X_j)}}$$
$$\overset{symm.}{=} \frac{1}{n^2} \sum\limits_{i=1}^n{V(X_i) + \frac{2}{n^2}\sum\limits_{i,j=1, i > j}^n{Cov(X_i,X_j)}}$$
$$\sum\limits_{j=1}^n{\sum\limits_{i=j+1}^n{Cov(X_i,X_j)}}$$
$$= \sum\limits_{j=1}^n{\sum\limits_{i=j+1}^{\min \{n,j+k-1\}}{\underbrace{Cov(X_i,X_j)}_{\leq M}}}$$
da für $i \geq j+k: Cov(X_i, X_j) = 0$
$$\Rightarrow V(\bar{X_n}) \leq \frac{1}{n^2}n \cdot M + \frac{2}{n^2} n \cdot (k-1) \cdot M$$
$$= \frac{(2k-1)M}{n}$$
Sei $\epsilon > 0.$
$$\Rightarrow \Prim(|\bar{X_n}-m| \geq \epsilon) \overset{Tsch.}{\leq} \frac{V(\bar{X_n})}{\epsilon^2} \leq \frac{(2k-1)M}{n \epsilon^2} \overset{n \rightarrow \infty}{\rightarrow} 0$$
b) $Y_1, Y_2, \ldots$ Folge unabh. Würfelwürfe.
$$A_j := \{Y_j < Y_{j+1}\}$$

wir betrachten $X_j := 1_{\{A_j\}}$.
\newline
Es gilt $Var(X_j) \leq 1 < \infty$
$$\E(X_j) = \underline{\Prim(A_j)}$$
es gilt:
$$1 = \Prim(Y_j < Y_{j+1}) + \underbrace{\Prim(Y_j > Y_{j+1})}_{\overset{symm.}{=} \Prim(Y_j < Y_[j+1}) + \underbrace{\Prim(Y_j = Y_{j+1})}_{ = \sum\limits_{i=1}^6{\Prim(Y_j = Y_{j+1}|Y_j = i) \cdot \Prim(Y_j = i)} = \sum\limits_{i=1}^6{\underbrace{\Prim(Y_{j+1}=i|Y_j = i)}_{\overset{unabh.}{=} \underbrace{\Prim(Y_{j+1}=i)}_{= \frac{1}{6}}}} \cdot \underbrace{\Prim(Y_j = i)}_{= \frac{1}{6}} = \frac{1}{6}}$$

$$\Rightarrow \Prim(A_j) = \frac{5}{12}$$
und für $|i-j| \geq 2$ gilt:
$$1_{A_j} = 1_{\{Y_j < Y_{j+1}\}}$$ und
$$1_{A_i} = 1_{\{Y_i < Y_{i+1}\}}$$ sind unabh. (nach Blockungslemma)

$$\overset{a)}{\Rightarrow} \Prim(|\bar{X_n} - \frac{5}{12}| \geq \epsilon) \overset{n \rightarrow \infty}{\rightarrow} 0. \qed$$

\section{A28}
Für $n \in \N$
$$K_n = Y_1 \cdot \ldots \cdot Y_n$$ mit $\Prim(Y_i = \frac{5}{3}) = \frac{1}{2} = \Prim(Y_i = \frac{1}{2})$
\newline
a) es gilt $\E(Y_i) = \frac{1}{2} \cdot \frac{5}{3} + \frac{1}{2} \cdot \frac{1}{2} = \frac{13}{12}$
$$\E(K_n) = \E (Y_1 \cdot \ldots \cdot Y_n) \overset{unabh.}{=} \E(Y_1) \cdot \ldots \cdot \E(Y_n) = \left(\frac{13}{12} \right)^n \underset{(n \rightarrow \infty)}{\rightarrow} \infty$$

b) $Z_i := ln(Y_i)$
$$\Rightarrow \E(Z_i) = \frac{1}{2} \cdot ln \left(\frac{5}{3} \right) + \frac{1}{2} ln \left( \frac{1}{2} \right ) = \underbrace{ln \left (\frac{5}{6} \right)^{\frac{1}{2}}}_{=: \mu} < 0$$
es gilt $ln(K_n) = \sum\limits_{i=1}^n{Z_i}$
$$\Rightarrow \frac{1}{n} ln(K_n) \overset{p}{\rightarrow} \mu$$ (SGGZ für $Z_1, Z_2, \ldots$)
\newline
d.h. $\Prim(|\frac{1}{n} ln(K_n) - \mu| \geq \delta) \overset{n \rightarrow \infty}{\rightarrow} 0 \quad \forall \delta > 0$
$$\Rightarrow \Prim(\frac{1}{n}ln(K_n) - \mu \geq \delta) \overset{n \rightarrow \infty}{\rightarrow} 0$$
Sei nun $\epsilon > 0$ und $\delta \in (0, |\mu|)$
\newline
Dann gilt $e^{n \delta + n \mu} = e^{n(\delta - |\mu|)}$
\newline
d.h. $\exists m \in \N \quad \forall n \geq m \quad e^{n(\delta - |\mu|)} \leq \epsilon$
$$\Rightarrow \lim\limits_{n \rightarrow \infty}{\Prim(K_n \geq \epsilon)} \leq \lim\limits_{n \rightarrow \infty}{\Prim(K_n \geq e^{n(\delta - |\mu|)})} = \lim\limits_{n \rightarrow \infty}{\Prim(\frac{1}{n} ln(K_n)- \mu \leq \delta)} = 0$$
$$K_n > 0 \Rightarrow \lim\limits_{n \rightarrow \infty}{\Prim(|K_n - 0| \geq \epsilon)} = 0$$
d.h. $K_n \overset{p}{\rightarrow} 0.$

\section{A29}
a) $a,c > 0$
$$\Prim(X \leq c) \overset{X \geq 0}{=} \E[1_{[0,c]}(X)]$$
es gilt
$$1_{[0,c]}(x) \leq e^{a(c-x)}$$

\begin{itemize}
	\item $x \notin [0,c] \colon 1_{[0,c]}(x) = 0 \leq e^{a(c-x)}$
	\item $x \in [0,c] \colon 1_{[0,c]}(x) = 1 \leq e^{a(c-x)}$, da $a(c-x) \geq 0.$
\end{itemize}

Aus der Monotonie des Erwartungswertes folgt
$$\E[1_{[0,c]}(X)] \leq \E[e^{a(c-X)}] = e^{ac} \E[\underbrace{e^{-aX}}_{\leq 1}] \leq e^{ac}$$
$\Rightarrow e^{-aX}$ ist integrierbar + Beh.
\newline
b) $$\E (X) \geq \E(X \cdot 1_{\{X \geq c\}})$$ \footnote{wegen Monotonie}
$$\geq \E(c \cdot 1_{\{X \geq c\}}) = c \cdot \Prim(X \geq c)$$
$\Rightarrow$ Beh.

\section{Ergänzung zur Vorlesung}
Sei $S_n \sim Bin(n,p)$. Dann gilt
$$\Prim(S_n \leq k) = 1- \frac{n!}{k! (n-k-1)!} \int\limits_{0}^p{t^k (1-t)^{n-k-1} dt.}$$

\begin{proof}
	Beweis per vollständiger Induktion über $k = 0, \ldots, n$.
	\begin{enumerate}
		\item $k=0$:
		$$\Prim(S_n \leq 0) = (1-p)^n$$
		$$1- \frac{n!}{\underbrace{0!(n-1)!}_{n}} \underbrace{\int\limits_{0}^p{(1-t)^{n-1} dt}}_{[-\frac{1}{n}(1-t)^n]_0^p} = 1-n(-\frac{1}{n} (1-p)^n + \frac{1}{n}) = (1-p)^n$$
		\item $k \leadsto k+1$ für $k \leq n-1$
		$$\Prim(S_n \leq k+1) = \Prim(S_n \leq k) + \underbrace{\Prim(S_n = k+1)}_{{n \choose k+1} p^{k+1} (n-p)^{n-k-1}}$$
		$$1- \frac{n!}{k+1!(n-k-2)!} \underbrace{\int\limits_{0}^p{\underbrace{t^{k+1}}_{u(t)} \underbrace{(1-t)^{n-k-2}}_{v^\prime(t)} dt}}_{I_{k+1}}$$ \footnote{partielle Integration}
		$$\Rightarrow I_{k+1} = [- \frac{1}{n-k-1} t^{k+1} (1-t)^{n-k-1}]_0^p - \int\limits_0^p{(k+1)t^k(- \frac{1}{n-k-1}) (1-t)^{n-k-1} dt.}$$
		$$\Rightarrow I_{k+1} = - \frac{1}{n-k-1}p^{k+1}(1-p)^{n-k-1} + \frac{k+1}{n-k-1} \int\limits_0^p{t^k (1-t)^{n-k-1} dt}$$
		d.h. die rechte Seite der Gleichung
		$$1 + \frac{n!}{(k+1)!(n-k-1)!} p^{k+1} (1-p)^{n-k-1} - \frac{n!}{k!(n-k-1)!} \int\limits_0^p{t^k (1-t)^{n-k-1} dt}$$
		$$= \Prim(S_n \leq k) + \Prim(S_n = k+1)$$
	\end{enumerate}
\end{proof}

D.h. $S_n^{(p)} \sim Bin(n,p)$ ist stochastisch monoton (wachsend) in $p$, also $\Prim(S_n^{(p_1)} \geq k) \leq \Prim(S_n^{(p_2)} \geq k)$ für $p_1 \leq p_2.$

\section{A26}
a) $\Omega_k := \{ \omega \in (a_1, \ldots, a_r) \in Kom_{r, \neq}^s \colon a_1 = k\}, \widetilde{p}$ Gleichverteilung auf $\Omega_k$
$$\Rightarrow |\Omega_k| = {s-k \choose r-1} \quad (a_2 < \ldots < a_r \text{ aus } k+1, \ldots,s \text{ ziehen})$$
$$|\{X_{(r)} = j\}| = {j-k-1 \choose r-2} \quad (a_2 < \ldots < a_{r-1} \text{ aus } k+1, \ldots, j-1 \text{ ziehen})$$
$\Rightarrow \text{Beh.}$

\chapter{02.02.2012}
\section{A30}
$\vartheta \in \Theta = \N$
\newline
$X_1, \ldots, X_n$ unabh. ZVen, identisch verteilt mit $\Prim_\vartheta(X_i = x_i) = \frac{1}{\vartheta}$ für $x_i \in \{1, \ldots, \vartheta\}$ \newline
$x = (x_1, \ldots, x_n)$ Beobachtung, $x \in \N^n$ \newline
$X := (X_1, \ldots, X_n)$
\paragraph{a)}
$$L_x(\vartheta) = \Prim_\vartheta(X=x)$$
$$= \Prim_\vartheta(X_1 = x_1, \ldots, X_n = x_n)$$
$$L_x(\vartheta) = \begin{cases} (\frac{1}{\vartheta})^n & \max\limits_{1 \leq j \leq n}{x_j} \leq \vartheta \\ 0 & \text{ sonst } \end{cases}$$
$$\Rightarrow L_x(\vartheta) = \frac{1}{\vartheta^n} \cdot 1_{\{\max \limits_{1 \leq j \leq n}{x_j} \leq \vartheta\}}$$

\paragraph{b)}
\begin{enumerate}
	\item $\vartheta < \max\limits_{1 \leq j \leq n}{x_n} \colon L_x(\vartheta) = 0$
	\item $\vartheta \geq \max\limits_{1 \leq j \leq n}{x_j} \colon L_x(\vartheta)  = \frac{1}{\vartheta^n} > 0, L_x$ fallend in $\vartheta$.
\end{enumerate}
$\Rightarrow \hat{\vartheta}_n = \hat{\vartheta}_n(X_1, \ldots, X_n) = \max\limits_{1 \leq j \leq n}{X_j}$ \newline
$\hat{\vartheta}_n$ ist ML-Schätzer für $\vartheta$.

\paragraph{c)} $\Prim_\vartheta(\hat{\vartheta}_n \leq k) = \Prim_\vartheta(\max\limits_{1 \leq j \leq n}{X_j} \leq k)$
$$= \prod\limits_{j=1}^n{\Prim_\vartheta(X_j \leq k)} = (\frac{k}{\vartheta})^n, \quad k = 1, \ldots, \vartheta.$$
$$\Rightarrow \Prim_\vartheta(\hat{\vartheta}_n=k) =$$
$$\Prim_\vartheta(\hat{\vartheta}_n \leq k) - \Prim_\vartheta(\hat{\vartheta}_n \leq k-1)$$
$$= (\frac{k}{\vartheta})^n - (\frac{k-1}{\vartheta})^n$$

\paragraph{d)}
$$\E_\vartheta[\hat{\vartheta}_n] = \sum\limits_{k=1}^{\vartheta}{k \cdot ((\frac{k}{\vartheta})^n - (\frac{k-1}{\vartheta})^n)}$$
$$= \sum\limits_{k=1}^{\vartheta}{\frac{k^{n+1}}{\vartheta^n} - \sum\limits_{k=1}^{\vartheta}{\frac{(k-1)^{n+1}}{\vartheta^n} - \sum\limits_{k=1}^{\vartheta}{\frac{(k-1)^n}{\vartheta^n}}}}$$
$$= \vartheta - \frac{1}{\vartheta^n} \sum\limits_{k=2}^{\vartheta}{(k-1)^n} < \vartheta, \quad \vartheta \geq 2$$
$\Rightarrow \hat{\vartheta}_n$ ist \underline{nicht} erwartungstreu.

\paragraph{e)}
nach d) gilt
$$\E_\vartheta(\hat{\vartheta}_n) = \vartheta - \frac{1}{\vartheta^n} \sum\limits_{k=2}^n{(k-1)^n}$$
und
$$0 \leq \frac{1}{\vartheta^n} \sum\limits_{k=2}^{\vartheta}{\underbrace{(k-1}_{\leq \vartheta-1})^n \leq \frac{1}{\vartheta^n} \cdot (\vartheta-1) \cdot (\vartheta-1)^n}$$
$$= (\vartheta-1) \cdot (\frac{\vartheta-1}{\vartheta})^n \overset{n \rightarrow \infty}{\rightarrow} 0$$
d.h. $\E_\vartheta(\hat{\vartheta}_n) \rightarrow \vartheta \quad (n \rightarrow \infty)$. \newline
$\Rightarrow \hat{\vartheta}_n$
 ist asymptotisch erwartungstreu.
 \newline
 Zu zeigen:
 $$\hat{\vartheta}_n \overset{\Prim_\vartheta}{\rightarrow} \vartheta \quad \forall \vartheta \in \Theta = \N$$
 sei $0 < \epsilon < 1$.
 $$\Prim(|\hat{\vartheta}_n - \vartheta| \geq \epsilon)$$
 $$= \Prim(\hat{\vartheta}_n \leq \vartheta - 1)$$
 (da $\vartheta \in \N, \hat{\vartheta}_n \in \{1, \ldots, \vartheta\}$)
 
 $$= (\frac{\vartheta-1}{\vartheta})^n \rightarrow 0 \quad (n \rightarrow \infty)$$
 Sei $\hat{\epsilon} \geq 1:$
 $$\Prim(|\hat{\vartheta}_n- \vartheta|  \geq \hat{\epsilon}) \leq \Prim(|\hat{\vartheta}_n - \vartheta| \geq \epsilon) \text{ für ein } \epsilon> 1.$$
 $\Rightarrow (\hat{\vartheta}_n)_{n \in \N}$ ist konsistent.
 
 \paragraph{f)}
 $\widetilde{\vartheta_n} := \frac{\hat{\vartheta}_n^{n+1}- (\hat{\vartheta}_n -1)^{n+1}}{\hat{\vartheta}_n^n - (\hat{\vartheta}_n - 1)^n}$
 $$\E_\vartheta(\underbrace{\widetilde{\vartheta_n}}_{= f(\hat{\vartheta}_n)}) = \sum\limits_{k=1}^{\vartheta}{f(k) \cdot \Prim(\hat{\vartheta}_n = k)}$$
 $$= \sum\limits_{k=1}^{\vartheta}{\frac{k^{n+1}- (k-1)^{n+1}}{k^n - (k-1)^n} \cdot ((\frac{k}{\vartheta})^n - (\frac{k-1}{\vartheta})^n)}$$
 $$= \sum\limits_{k=1}^\vartheta{\frac{k^{n+1} - (k-1)^{n+1}}{\vartheta^n}} \overset{\text{Teleskopsumme}}{=} \frac{\vartheta^{n+1}}{\vartheta^n} - \frac{0}{\vartheta^n} = \vartheta$$
 
 $\Rightarrow \widetilde{\hat{\vartheta}_n}$ ist erwartungstreu.
 
 \paragraph{g)}
 $\hat{\vartheta}_{10}(x_1, \ldots, x_{10}) = 113$
 $$\rightarrow \widetilde{\vartheta}_{10} = f(113) \approx 123,76$$
 
 
 \section{A32}
 \paragraph{a)}
 zu zeigen: $\alpha^{-\frac{1}{n}} \cdot \hat{\vartheta}_n$ ist eine obere Konfidenzschranke für $\vartheta$ zum Niveau $1-\alpha$.
 
 $$\Prim_\vartheta(\vartheta \leq \alpha^{-\frac{1}{n} \hat{\vartheta}_n})$$
 $$= \Prim_\vartheta(\hat{\vartheta}_n \geq \alpha^{\frac{1}{n}} \cdot \vartheta) = \underbrace{1 - \Prim_\vartheta(\hat{\vartheta}_n < \vartheta \sqrt[n]{\alpha})}_{=: p_\alpha}$$
 
 \begin{enumerate}
 	\item $\vartheta \sqrt[n]{\alpha} \in \N \colon$
 	$$\Prim_\vartheta(\hat{\vartheta}_n < \vartheta \sqrt[n]{\alpha}) = \left(\underbrace{\frac{\vartheta \sqrt[n]{\alpha}-1}{\vartheta}}_{\sqrt[n]{\alpha} - \frac{1}{\vartheta}}\right )^n < \alpha$$
 	\item $\vartheta \sqrt[n]{\alpha} \notin \N \colon$
 	$$\Prim_\vartheta(\hat{\vartheta}_n < \vartheta \sqrt[n]{\alpha}) = \left(\frac{\lfloor \vartheta \sqrt[n]{\alpha} \rfloor}{\vartheta}\right)^n < \alpha$$
 \end{enumerate}
 
 $$\Rightarrow \Prim_\vartheta(\vartheta \leq \alpha^{-\frac{1}{n}}) > 1- \alpha \qquad \qed$$
 
 \paragraph{b)}
 $$\Prim_\vartheta(\vartheta \leq 1.1 \cdot \hat{\vartheta}_n) \geq 0.99$$
 $$\Leftrightarrow \Prim_\vartheta(\hat{\vartheta}_n \geq \frac{\vartheta}{1.1}) \geq 0.99$$
 $$\Leftrightarrow 1- \Prim_\vartheta(\hat{\vartheta}_n < \frac{\vartheta}{1.1}) \geq 0.99$$
 $$\Leftrightarrow 1- \left(\frac{\lfloor\frac{\vartheta}{1.1}\rfloor}{\vartheta} \right)^n \geq 0.99$$
 $$\Leftrightarrow 1 - \left(\frac{10}{11}\right)^n \geq 0.99$$
 $$\Leftrightarrow n \geq 49$$
 
 \section{A31}
 $X_1, \ldots, X_n$ unabhängig identisch verteilt mit $Po(\lambda)$ \footnote{Poisson-Verteilung}
 \newline
 ZGWS:
 $$\lim\limits_{n \rightarrow \infty}{\Prim_\lambda(\left|\frac{\sum\limits_{i=1}^n{X_i} - n \lambda}{\sqrt{n \lambda}}\right|) \leq h} = \phi(h) - \phi(-h) = 2 \phi(h)-1$$
 $$\bar{X_n} := \frac{1}{n} \sum\limits_{i=1}^n{X_i}.$$
 Es gilt
 $$\left | \frac{n \cdot \bar{X_n} - n \lambda}{\sqrt {n \lambda}}  \right | \leq h$$
 $$\Leftrightarrow (n \bar{X_n} - n \lambda)^2 \leq h^2 \cdot n \lambda$$
 $$\Leftrightarrow n^2 \lambda^2 - n h^2 \lambda - 2 n^2 \bar{X_n} \lambda + n^2 \bar{X_n}^2 \leq 0$$
 $$\Leftrightarrow \lambda^2 - \lambda (2 \bar{X_n} + \frac{h^2}{n}) + \bar{X_n}^2 \leq 0$$ \footnote{nach oben geöffnete Parabel}
 $"=0"$ für $\lambda_{1,2} = (\bar{X_n} + \frac{h^2}{2n}) \overset{+}{-} \underbrace{\sqrt{(\bar{X_n} + \frac{h^2}{n})^2 - \bar{X_n}^2}}_{= \sqrt{\bar{X_n} \frac{h^2}{n} + \frac{h^4}{4n^2}}}$ \newline
 Definiere
 $$U_n := \bar{X_n} + \frac{h^2}{2n} - \sqrt{\bar{X_n} \frac{h^2}{n} + \frac{h^4}{4n^2}}$$
 $$O_n := \bar{X_n} + \frac{h^2}{2n} + \sqrt{\bar{X_n} \frac{h^2}{n} + \frac{h^4}{4n^2}}$$
 
 Dann gilt $U_n \leq \lambda \leq O_n \Leftrightarrow \left | \frac{n \bar{X_n} - n \lambda}{\sqrt{n \lambda}} \right | \leq h$
 
 $$1-\alpha \overset{!}{=} 2 \phi(h)-1$$
 $$\Leftrightarrow \phi(h) = \frac{2-\alpha}{2}$$
 $$\Leftrightarrow h = \phi^{-1}(\frac{2-\alpha}{2})$$
 $$= \phi^{-1}(1-\frac{\alpha}{2})$$
 
 Für $h = \phi^{-1}(1-\frac{\alpha}{2})$ ist also $[U_n(h), O_n(h)]$ ein asymptotisches Konfidenzintervall zum Niveau $1 - \alpha$.
 
 \section{A33}
 $X_1, \ldots, X_n \overset{u.i.v.}{\sim} \mathcal{G}(\vartheta) \quad \vartheta \in \Theta= (0,1)$ \footnote{Geometrische Verteilung}
 
 \paragraph{a)}
 $$L_x(\vartheta) = \Prim_\vartheta((X_1, \ldots, X_n) = x)$$
 $$= \prod\limits_{i=1}^n{\Prim_\vartheta(X_i = x_i)} = \prod\limits_{i=1}^n{(\vartheta \cdot (1-\vartheta)^{x_i})}$$
 $$= \vartheta^n \cdot (1-\vartheta)^{\sum\limits_{i=1}^n{x_i}}$$
 
 $$\bar{X_n} := \frac{1}{n} \sum\limits_{i=1}^n{X_i},$$
 $$\bar{x_n} := \frac{1}{n} \sum\limits_{i=1}^n{x_i}$$
 $$\Rightarrow \log L_x (\vartheta) = n \cdot \log(\vartheta) + n \cdot \bar{x_n} \log(1-\vartheta)$$
 $$\frac{\partial}{\partial \vartheta} \log L_x(\vartheta) = \frac{n}{\vartheta} - n \bar{x_n} \cdot \frac{1}{1-\vartheta} \overset{!}{=} 0$$
 $$\Leftrightarrow \frac{1-\vartheta}{\vartheta} = \bar{X_n} \Leftrightarrow \vartheta = \frac{1}{1+ \bar{x_n}}$$
 $$\frac{\partial^2}{(\partial \vartheta)^2} = - \frac{n}{\vartheta^2}- n \bar{x_n} \frac{1}{(1-\vartheta)^2}< 0$$
 $\Rightarrow \hat{\vartheta}_n = \frac{1}{1+ \bar{X_n}}$ ist ML-Schätzer
 
 $$\hat{\vartheta}_n = f(\bar{X_n})$$
 Hinweis: $f(\bar{X_n}) > f(a) + f^\prime(a) \cdot (\bar{X_n}-a) \quad \forall a > 0$ (da $\bar{X_n}$ \underline{nicht} konstant, insbesondere gilt nicht $\bar{X_n} \equiv a$)
 
	$$\E_\vartheta \hat{\vartheta}_n) > \E(f(a) + f^\prime(a) (\bar{X_n} - a))$$
	$$= f(a) + f^\prime(a) (\E(\bar{X_n}) - a) \quad \forall a > 0$$
	insbesondere für $a= \E(\bar{X_n}) = \E X_1 = \frac{1}{1-\vartheta}$ \footnote{durch die Unabhängigkeit} \newline
	$\Rightarrow f(a) = \vartheta$ und $\E_\vartheta(\hat{\vartheta}_n) > \vartheta$ 
 
\end{document}
